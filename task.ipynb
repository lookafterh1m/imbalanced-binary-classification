{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3272b815-0139-45ab-a741-1d4aa9f0dbf7",
   "metadata": {},
   "source": [
    "# Imbalanced bainary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c953fa1-b0a3-49f3-8078-86ed44e5ca3d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5f7e2f-a3f0-4638-9b4c-8a309fc916e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f992c978-3ce6-4ce6-98bb-defad2e4617a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/Training.xlsb', index_col='ID', engine='pyxlsb')\n",
    "pd.set_option('display.max_columns', 30)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b5f237-c21f-4763-9359-129775c54979",
   "metadata": {},
   "source": [
    "Splitting features at categorical and numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ff5cd3-0a45-4562-9aaa-7d37040c16b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = []\n",
    "cat_features = []\n",
    "for col in df.columns[:-1]:\n",
    "    if df[col].dtype == 'object':\n",
    "        cat_features.append(col)\n",
    "    else:\n",
    "        num_features.append(col)\n",
    "df.shape, num_features, cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f157af-d086-4a72-908f-a9e1d1345631",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa285ad-0681-4b87-9bff-16029cf72b47",
   "metadata": {},
   "source": [
    "Let's take a look how well power transformation will scale our data. Save it to `scaled`, in order to include this transformation into pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ca3582-1d6f-4bc9-b2ef-04f91f5a1300",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import power_transform\n",
    "\n",
    "scaled = pd.DataFrame(power_transform(df[num_features]), columns=num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f04a13-298d-4ee6-a596-072dcec1db07",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7717040c-f4fe-4b08-92ee-45c1bd6c508e",
   "metadata": {},
   "source": [
    "Histogram and correlogram below show that power transformation did great job in scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d363905-23bd-479d-aa8a-3bc1aaa8cd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(scaled.L);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500bf6af-4dc3-4bc3-8bc9-073387baf467",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(scaled[num_features[:-1]]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b94cfb1-a0aa-4dfb-9a92-4f3a0669431d",
   "metadata": {},
   "source": [
    "Scatter plot below shows how imbalanced classes are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cb7eea-d804-45e3-8ba4-11381d3da6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = scaled.columns[0]\n",
    "b = scaled.columns[2]\n",
    "plt.scatter(scaled[a], scaled[b], c=df['MARKER']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79ffa16-9691-472d-ae41-5e29486b25ee",
   "metadata": {},
   "source": [
    "I found out that features below (`N`, `P`, `V`) are good to encode ordinary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d611a3-4fdd-48b9-ab6d-4306c78acdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_to_ord_encode = ['N', 'P', 'V']\n",
    "for cat in cat_to_ord_encode:\n",
    "    print(cat)\n",
    "    print(df[cat].value_counts(), '\\n')\n",
    "    if cat in cat_features:\n",
    "        cat_features.remove(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dc66ae-7a44-48fa-b9da-aeb84530af32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = df.drop('MARKER', axis=1), df['MARKER']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ed9b72-c929-403d-ad59-823e88144cb1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0bc749-6d57-46ca-a383-635440d01a92",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pipeline construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd534d50-9a47-45f3-b3c4-06d2e7f8b6b5",
   "metadata": {},
   "source": [
    "Since classes are very imbalanced it's not representative to use accuracy for scoring. That's why we'll focus on sensitivity score and `classification_report`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dda3338-b013-4d12-8cf9-9761bcf25595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.metrics import specificity_score\n",
    "from imblearn.metrics import sensitivity_score\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "def scoring(y_test, y_pred, display_report=False):\n",
    "    \"\"\"\n",
    "    Function to display specificity and sensitivity scores. Also displays classification report\n",
    "    ---\n",
    "    params:\n",
    "        y_test - iterable, one-dimensional array, actual values.\n",
    "        y_pred - iterable, one-dimensional array, predicted values.\n",
    "        display_report - wether dispaly or not classification report\n",
    "    \"\"\"\n",
    "    print(f\"Specificity: {specificity_score(y_test, y_pred)}\")\n",
    "    print(f\"Sensitivity: {sensitivity_score(y_test, y_pred)}\")\n",
    "    if display_report:\n",
    "        print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28ac3d3-c50b-4f53-af65-b44ea137117e",
   "metadata": {},
   "source": [
    "To balance classes I will perform over-sampling using Adaptive Synthetic Sampling approach. I have chosen over-sampling but not under-sampling in order to save dependencies that might be useful for learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aa154b-cd06-4b8d-a589-14e1c88f2fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, PowerTransformer, OrdinalEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "\n",
    "preprocessing = make_column_transformer(\n",
    "    (OrdinalEncoder(), cat_to_ord_encode),\n",
    "    (OneHotEncoder(), cat_features),\n",
    "    (PowerTransformer(), num_features)\n",
    ")\n",
    "\n",
    "logreg_pip = make_pipeline(\n",
    "    preprocessing,\n",
    "    ADASYN(n_jobs=-1),\n",
    "    LogisticRegression(n_jobs=-1, max_iter=5000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e371438-8a2c-4685-9f7f-53f93d62e8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pip.fit(X_train, y_train)\n",
    "y_pred_logreg = logreg_pip.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0267342d-afea-4b1c-8b77-9181b7c39c16",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Interpreting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa690de-5bc5-4f04-8e0f-f4f72ea21af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring(y_test, y_pred_logreg, display_report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3333451-b72a-45ce-b679-a482a454c6c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Boosting algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b84a2d1-9f26-4977-8f70-80df90d4bc65",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pipeline construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6612c4b4-b8ad-4a56-9af1-60cbf9335b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import EasyEnsembleClassifier, RUSBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from xgboost import XGBRFClassifier\n",
    "\n",
    "rus_params = {\n",
    "    'rusboostclassifier__n_estimators': [50, 100, 200],\n",
    "    'rusboostclassifier__sampling_strategy': [0.1, 0.3, 0.5, 'auto'],\n",
    "    'rusboostclassifier__learning_rate': [0.7, 1, 1.3]\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'xgbrfclassifier__n_estimators': [50, 100, 200],\n",
    "    'xgbrfclassifier__learning_rate': [0.7, 1, 1.3],\n",
    "    'xgbrfclassifier__reg_lambda': [1, 0.7, 0.5, 0.25, 0.1]\n",
    "}\n",
    "\n",
    "rus_pip = make_pipeline(\n",
    "    preprocessing,\n",
    "    ADASYN(n_jobs=-1),\n",
    "    RUSBoostClassifier()\n",
    ")\n",
    "\n",
    "xgb_pip = make_pipeline(\n",
    "    preprocessing,\n",
    "    ADASYN(n_jobs=-1),\n",
    "    XGBRFClassifier(\n",
    "        n_jobs=-1, predictor='cpu_predictor',\n",
    "        use_label_encoder=False, verbosity=1\n",
    "    )\n",
    ")\n",
    "\n",
    "rus_grid = GridSearchCV(rus_pip, param_grid=rus_params, n_jobs=-1)\n",
    "xgb_grid = GridSearchCV(xgb_pip, param_grid=xgb_params, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63fe70f-8df0-4715-afbb-558aea851967",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    rus_grid.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0841364-260d-40c0-be9e-ca9335bd4bb9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Results for RUSBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3244e39-8a5f-4e4f-b823-790c1f1fe30e",
   "metadata": {},
   "source": [
    "Since RUSBoost [uses under-sampling](https://imbalanced-learn.org/stable/references/generated/imblearn.ensemble.RUSBoostClassifier.html) to balance data, there is no point in over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccad554-e18c-4903-b22e-a8862b1c9949",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rus = rus_grid.predict(X_test)\n",
    "scoring(y_test, y_pred_rus, display_report=True)\n",
    "rus_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e53a625-68dd-4f8c-99cf-3dd5da59870d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Results for XGBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faac1a56-6f66-447a-b2d0-98b122cc4c7f",
   "metadata": {},
   "source": [
    "For XGBoostClassifier I used same preprocessing pipeline as for Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9191f525-dad6-463d-b080-416b4c7048ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_grid.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95521f5f-1b05-4d2a-9f75-372e382e76c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = xgb_grid.predict(X_test)\n",
    "scoring(y_test, y_pred_xgb, display_report=True)\n",
    "xgb_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e59cd3b-baf3-41d0-bc6a-5b64b3e5f828",
   "metadata": {},
   "source": [
    "**Thank you for your time! I will apreciate to see your feedback and hope for further cooperation.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
